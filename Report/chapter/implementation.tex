\chapter{Implementation}

The FFT application has been implemented in C/C++, CUDA, OpenCL, DirectCompute and OpenGL on a GeForce GTX 670 and Radeon R7 260X graphics card and a Core i7 3770K 3.5GHz CPU.

\section{Benchmark application GPU}

\subsection{FFT implementation}

\subsubsection{Setup}

The implementation of the FFT algorithm on a GPU can be broken down into a few steps, see figure \ref{fig:algorithm-overview} for an simplified overview. The application setup differs among the tested technologies, however some steps can be generalized; get platform and device information, allocate device buffers and upload data to device.
\begin{figure}
	\centering
	\includestandalone[width=\textwidth]{figures/overview}
	\caption{Overview of the events in the algorithm.}
	\label{fig:algorithm-overview}
\end{figure}

The next step is to calculate the specific FFT arguments for a $N$-point sequence for each kernel. The most important difference between devices and platforms are local memory capacity and thread and block configuration. Threads per block was selected for the best performance. See table \ref{tab:threads-per-block} for details.
\begin{table}
	\centering
	\includestandalone[width=\textwidth]{tables/threadsperblock}
	\caption{Shared memory size, threads and block configuration per device.}
	\label{tab:threads-per-block}
\end{table}

\subsubsection{Butterfly}

The implementation of a $N$-point radix-2 FFT algorithm have $\log_2 N$ stages with $N/2$ butterfly operations per stage. A butterfly operation is an addition, a subtraction, followed by a multiplication by a twiddle factor, showed in figure \ref{fig:butterfly}.
\begin{figure}[h]
	\centering
	\input{figures/butterfly}
	\caption{Butterfly operations}
	\label{fig:butterfly}
\end{figure}

\subsubsection{Thread and block scheme}

The thread and block scheme was one butterfly per thread, so that a sequence of sixteen points require eight threads. Each platform was configured to a number of threads per block (see table \ref{tab:threads-per-block}) and any sequences twice as long as the threads per block configuration needed the algorithm to be split over several blocks. If the sequence exceed one block then the sequence is mapped over multiple blocks using the \texttt{blockIdx.y} dimension. The block dimension \texttt{blockIdx.x} is used to calculate sequence id in when running a large batch, the block dimensions are limited to $2^{31}$, $2^{16}$, $2^{16}$ respectively for \texttt{x}, \texttt{y}, \texttt{z}. Example: if the threads per block limit is two, then four blocks would be needed for a sixteen point sequence.
\begin{figure}
	\input{figures/exampleflow}
	\caption{Example flow graph of a sixteen-point FFT using (stage 1 and 2) Cooley-Tukey algorithm and (stage 3 and 4) constant geometry algorithm. The solid box is the bit-reverse order output. Dotted boxes are separate kernel launches, dashed boxes are data transfered to local memory before computing the remaining stages.}
	\label{fig:flowgraph-16}
\end{figure}

\subsubsection{Synchronization}

Thread synchronization is only available within a block. When the sequence or partial sequence fitted within a block all data was transferred to local memory before completing the last stages. If the sequence was larger and required more then one block the synchronization was handled by launching several kernels executed in sequence. The kernel launched for block wide synchronization is called the global kernel and the kernel for thread synchronization within a block is called the local kernel. The global kernel had an implementation of the Cooley-Tukey FFT algorithm and the local kernel had constant geometry (same indexing for every stage). The last stage outputs from shared memory to the bit reversed index of the complete sequence. See figure \ref{fig:flowgraph-16} where the sequence length is sixteen and the thread per block is set to two.

\subsubsection{Calculation}

The indexing for the global kernel was calculated from the thread id and block id (\texttt{threadIdx.x} and \texttt{blockIdx.x} in CUDA) as seen in figure \ref{fig:code-global-index}. Input and output is done on the same index.
\begin{figure}
	\centering
	\lstset{language=C++}
	\begin{framed}
	\begin{lstlisting}
int tid     = blockIdx.x * blockDim.x + threadIdx.x,
    io_low  = tid + (tid & (0xFFFFFFFF << stages_left)),
    io_high = index1 + (N >> 1);
	\end{lstlisting}
	\end{framed}
	\caption{ CUDA example code showing index calculation for each stage in the global kernel, N is the total number of points. \texttt{io\_low} is the index of the first input in the butterfly operation and \texttt{io\_high} the index of the second.}
	\label{fig:code-global-index}
\end{figure}

Index calculation for the local kernel is done once for all stages, see figure \ref{fig:code-local-index}. These indexes are separate from the indexing in the global memory. The global memory offset depends on threads per block (\texttt{blockDim.x} in CUDA) and block id.
\begin{figure}
	\centering
	\lstset{language=C++}
	\begin{framed}
	\begin{lstlisting}
int n_per_block = N / gridDim.x.
    in_low      = threadId.x.
    in_high     = threadId.x + (n_per_block >> 1).
    out_low     = threadId.x << 1.
    out_high    = out1 + 1;
	\end{lstlisting}
	\end{framed}
	\caption{ CUDA example code showing index calculation for points in shared memory for the CUDA local kernel. }
	\label{fig:code-local-index}
\end{figure}

The last operation after the last stage is to perform the bit-reverse indexing operation, this is done when writing from shared to global memory. The implementation of bit reversing is available as a intrinsic integer instruction, see table \ref{tab:bit-reverse-intrinsics}. If instruction is not available figure \ref{fig:code-bit-reverse} shows the code used. The bit reversed value had to be right shifted the number of zeroes leading the number in a 32-bit int. Example of the bit-reverse index operation: index 8 of a 16 point sequence is bit-reversed to 1, in binary its 1000 reversed to 0001. Index 8 of a 32 point sequence is bit-reversed to 2, corresponds to 01000 to 00010. Figure \ref{fig:flowgraph-16} show the complete bit-reverse operations of a 16-point sequence in the output step after the last stage.

\begin{table}[h!]
	\centering
	\includestandalone[width=\textwidth]{tables/bit-reverse-intrinsics}
	\caption{Integer intrinsic bit-reverse function for different technologies.}
	\label{tab:bit-reverse-intrinsics}
\end{table}

\begin{figure}[h]
	\centering
	\lstset{language=C++}
	\begin{framed}
	\begin{lstlisting}
x = (((x & 0xaaaaaaaa) >> 1) | ((x & 0x55555555) << 1));
x = (((x & 0xcccccccc) >> 2) | ((x & 0x33333333) << 2));
x = (((x & 0xf0f0f0f0) >> 4) | ((x & 0x0f0f0f0f) << 4));
x = (((x & 0xff00ff00) >> 8) | ((x & 0x00ff00ff) << 8));
return((x >> 16) | (x << 16));
	\end{lstlisting}
	\end{framed}
	\caption{ Code returning a bit reversed unsigned integer where x is the input. Only 32-bit integer input and output. }
	\label{fig:code-bit-reverse}
\end{figure}

\subsection{FFT 2D implementation}

The FFT algorithm for two dimensional data, such as images, is first transformed row wise (each row as a separate sequence) and then a transform of each column. The implementation performs a row wise transformation and then transposes the whole image twice, see figure \ref{lst:cuda:host-2d-example}. A transformed image is shown in figure \ref{fig:twodimentransform}.

\begin{figure}[h!]
	\centering
	\begin{framed}
		\includestandalone[width=\textwidth]{code/cuda-host-2d}	
	\end{framed}
	\caption{CUDA host code for the 2D FFT algorithm.}
	\label{lst:cuda:host-2d-example}	
\end{figure}

\begin{figure}
	\centering
	\subfloat[Original image\label{image-1:lena}]{
		\includegraphics[keepaspectratio=true, scale=0.33]{images/lena.jpg}{}		
    }
    \hfill
    \subfloat[Magnitude representation\label{image-2:lena}]{
		\includegraphics[keepaspectratio=true, scale=0.33]{images/lena_transformed.jpg}{}
    }
	\caption{Original image \ref{image-1:lena} transformed and represented with a quadrant shifted magnitude visualization \ref{image-2:lena}. }
    \label{fig:twodimentransform}
\end{figure}

The difference between the FFT kernel for 1D and 2D are the indexing scheme. 2D are indexed as rows at \texttt{blockIdx.x} and columns at $\texttt{threadIdx.x} + \texttt{blockIdx.y} \cdot \texttt{blockDim.x}$. For 2D \texttt{blockIdx.z} is used as the sequence id in a batch.

\subsubsection{Transpose}

The transpose kernel uses a different index mapping of the 2D-data and blocks/threads then the FFT kernel. The data is tiled in a grid pattern where each tile represents one block, indexed by \texttt{blockIdx.x} and \texttt{blockIdx.y}. The tile size is a multiple of 32 for both dimensions and limited to the size of the shared memory buffer, see table \ref{tab:threads-per-block} for specific size per technology. To avoid banking issues, the last dimension is increased with one but not used. However, resolving the banking issue have little effect on total running-time so when shared memory is limited to 32768, the extra column is not used. The tiles rows and columns are diveded over the \texttt{threadIdx.x} and \texttt{threadIdx.y} index respectively. See figure \ref{lst:cuda:device-transpose} for code example. Example: The CUDA shared memory can allocate 49152 bytes and a single data point require $\texttt{sizeof(float)} \cdot 2 = 8$ bytes. That leaves room for a tile size of $64 \cdot (64 + 1) \cdot 8 = 33280$ bytes.

\begin{figure}[h!]
	\centering
	\begin{framed}
		\includestandalone[width=\textwidth]{code/cuda-device-transpose}	
	\end{framed}
	\caption{CUDA device code for the transpose kernel.}
	\label{lst:cuda:device-transpose}	
\end{figure}

The transpose kernel uses the shared memory and tiling of the image to avoid large strides through global memory. Each block represents a tile in the image. The first step is to write the complete tile to shared memory and synchronize the threads before writing to the output buffer. Both reading from the input memory and writing to the output memory is performed in close stride. Figure \ref{fig:transpose-memory} shows how the transpose is performed in memory.

\begin{figure}[h!]
	\centering
	\includestandalone[width=\textwidth]{figures/transpose-tile}
	\caption{Illustration of how shared memory is used in transposing an image. Input data is tiled and each tile is written to shared memory and transposed before written to the output memory. }
	\label{fig:transpose-memory}
\end{figure}

\section{Benchmark application CPU}

\subsection{FFT implementation in OpenMP}

The OpenMP implementation benefits in performance from calculating the twiddle factors in advance. The calculated values are stored in a buffer accessible from all threads. The next step is to calculate each stage of the FFT algorithm. Last is the output index calculation where elements are reordered. See figure \ref{fig:omp:overview} for an overview.

\begin{figure}
	\centering
	\includestandalone[width=\textwidth]{figures/omp-overview}
	\caption{OpenMP implementation overview transforming sequence of size $N$.}
	\label{fig:omp:overview}
\end{figure}

\subsubsection{Twiddle Factors}

The twiddle factor are stored for each butterfly operation. To save time, only the real part are calculated and the imaginary part is retrieved from the real parts due to the fact that $\sin(x) = \cos(\pi/2 + x)$ and $\sin(\pi/2 + x) = -\cos(x)$ to store. See figure \ref{tab:omp:twiddle-overview} for an example. The calculations will be split among the threads by static scheduling in two steps, first calculate the real values, secondly copy from real to imaginary.

\begin{table}[h!]
	\centering
	%\includestandalone[width=\textwidth]{figures/omp-twiddle-overview}
	\input{tables/omp-twiddle}
	\caption{Twiddle factor table $W$ for a 16-point sequence where $\alpha = (2 \cdot \pi) / 16$. Each row $i$ corresponds to the $i$th butterfly operation.}
	\label{tab:omp:twiddle-overview}
\end{table}

\subsubsection{Butterfly}

The same butterfly operation as the local kernel from previous section is used. The constant geometry on the CPU does not make the index calculations go away but it makes  The benefit from continues output indexes 

\subsubsection{Bit Reversed Order}

\subsection{FFT implementation in OpenMP}

